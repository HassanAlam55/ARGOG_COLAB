{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HassanAlam55/ARGOG_COLAB/blob/main/VectorDB_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2xB8tzXXj32"
      },
      "source": [
        "# Creating Vector DB for ARGOG Paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3rGp48GbBYJ"
      },
      "outputs": [],
      "source": [
        "# # install packages if they dont exist:\n",
        "# import subprocess\n",
        "# import sys\n",
        "\n",
        "# # Function to install a package if not already installed\n",
        "# def install_package(package_name, import_name=None):\n",
        "#     try:\n",
        "#         if import_name is None:\n",
        "#             import_name = package_name\n",
        "#         __import__(import_name)\n",
        "#     except ImportError:\n",
        "#         print(f\"{package_name} not found. Installing...\")\n",
        "#         subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
        "#     else:\n",
        "#         print(f\"{package_name} is already installed.\")\n",
        "\n",
        "# # List of packages to install with their import names if different\n",
        "# packages = [\n",
        "#     (\"datasets\", \"datasets\"),\n",
        "#     (\"pandas\", \"pandas\"),\n",
        "#     (\"llama-index\", \"llama_index\"),\n",
        "#     (\"chromadb\", \"chromadb\"),\n",
        "#     (\"openai\", \"openai\"),\n",
        "#     (\"dotenv\", \"dotenv\"),\n",
        "#     (\"llama_index.vector_stores\", \"llama_index.vector_stores\"),\n",
        "#     # (\"utils\", \"utils\")\n",
        "\n",
        "# ]\n",
        "\n",
        "# # Install each package\n",
        "# for package_name, import_name in packages:\n",
        "#     install_package(package_name, import_name)\n",
        "\n",
        "# # Check for `utils` module, typically custom or local\n",
        "# drive.mount('/content/drive')\n",
        "# import sys\n",
        "# sys.path.append('/content/drive/MyDrive/Colab Notebooks/ARGOG')\n",
        "# try:\n",
        "#     import utils\n",
        "# except ImportError:\n",
        "#     print(\"The 'utils' module is not found. Make sure it's available in your environment or install it manually.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb6x5_fwZhgY",
        "outputId": "142403a1-709f-4883-a4ba-9fa672c78d33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "datasets not found. Installing...\n",
            "pandas is already installed.\n",
            "llama-index not found. Installing...\n",
            "chromadb not found. Installing...\n",
            "openai is already installed.\n",
            "dotenv is already installed.\n",
            "llama-index-vector-stores-postgres not found. Installing...\n",
            "llama-index-vector-stores-chroma not found. Installing...\n",
            "nest_asyncio is already installed.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# install packages if they dont exist:\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Function to install a package if not already installed\n",
        "def install_package(package_name, import_name=None):\n",
        "    try:\n",
        "        if import_name is None:\n",
        "            import_name = package_name\n",
        "        # Use __import__ for top-level modules, import for submodules\n",
        "        if \".\" in import_name:\n",
        "            exec(f\"from {import_name.rsplit('.', 1)[0]} import {import_name.rsplit('.', 1)[1]}\")\n",
        "        else:\n",
        "            __import__(import_name)\n",
        "    except ImportError:\n",
        "        print(f\"{package_name} not found. Installing...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
        "    else:\n",
        "        print(f\"{package_name} is already installed.\")\n",
        "\n",
        "# List of packages to install with their import names if different\n",
        "packages = [\n",
        "    (\"datasets\", \"datasets\"),\n",
        "    (\"pandas\", \"pandas\"),\n",
        "    (\"llama-index\", \"llama_index\"),\n",
        "    (\"chromadb\", \"chromadb\"),\n",
        "    (\"openai\", \"openai\"),\n",
        "    (\"dotenv\", \"dotenv\"),\n",
        "    (\"llama-index-vector-stores-postgres\", \"llama_index.vector_stores\"), # Install the postgres vector store if you intend to use it\n",
        "    (\"llama-index-vector-stores-chroma\", \"llama-index-vector-stores-chroma\"),\n",
        "    (\"nest_asyncio\", \"nest_asyncio\")\n",
        "    # (\"utils\", \"utils\n",
        "\n",
        "]\n",
        "\n",
        "# Install each package\n",
        "for package_name, import_name in packages:\n",
        "    install_package(package_name, import_name)\n",
        "\n",
        "# Check for `utils` module, typically custom or local\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/ARGOG')\n",
        "try:\n",
        "    import utils\n",
        "except ImportError:\n",
        "    print(\"The 'utils' module is not found. Make sure it's available in your environment or install it manually.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GeeZunHHev5Q"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries for loading datasets, data manipulation, document processing, vector storage, and embeddings.\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "from llama_index.core import Document, StorageContext, VectorStoreIndex\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
        "import chromadb\n",
        "from llama_index.core.node_parser import TokenTextSplitter\n",
        "from utils import chunked_iterable, load_config\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "import openai\n",
        "import os\n",
        "from utils import *\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ogkjsIGaaLQt",
        "outputId": "262a5732-ca43-43ba-b3be-477b74f6a94c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Directory exists: /content/drive/MyDrive/Colab Notebooks/ARGOG\n",
            "sk-proj-NedhPl47SBdpZvVsIe2KT3BlbkFJspbYIje2ZfdzTrhdPqP5\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Verify the directory exists\n",
        "argog_path = '/content/drive/MyDrive/Colab Notebooks/ARGOG'\n",
        "if os.path.exists(argog_path):\n",
        "    print(f\"Directory exists: {argog_path}\")\n",
        "else:\n",
        "    print(f\"Directory does not exist: {argog_path}\")\n",
        "\n",
        "# Path to the .env file\n",
        "env_path = '/content/drive/MyDrive/Colab Notebooks/ARGOG/.env'\n",
        "\n",
        "# Load the .env file\n",
        "load_dotenv(dotenv_path=env_path)\n",
        "\n",
        "# Hardcoded values for easy adjustment\n",
        "CHUNK_SIZE = 1000 #only for db upload\n",
        "TOKEN_CHUNK_SIZE = 512\n",
        "CHUNK_OVERLAP = 50\n",
        "\n",
        "# Load the config file\n",
        "load_config()\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "print(openai.api_key)\n",
        "hf_read_token = os.getenv(\"HF_READ_TOKEN\")\n",
        "from huggingface_hub import login\n",
        "login(hf_read_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gA5zqiw6Vod6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "f1be7c04969b4614bfb4b96f7002fd80",
            "c11547de70064032be5fec2b5a449be0",
            "4781ef15205944ae8298872d29219d84"
          ]
        },
        "outputId": "f9a11f13-d4d3-455d-f2df-c490c0ff2ebf"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1be7c04969b4614bfb4b96f7002fd80",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/267 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c11547de70064032be5fec2b5a449be0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train.jsonl:   0%|          | 0.00/38.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4781ef15205944ae8298872d29219d84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/423 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load dataset and convert to DataFrame for easier manipulation\n",
        "dataset = load_dataset(\"jamescalam/ai-arxiv\")\n",
        "df = pd.DataFrame(dataset['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AQR29bCoQoau"
      },
      "outputs": [],
      "source": [
        "# Specify the titles of the required papers\n",
        "required_paper_titles = [\n",
        "    'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding',\n",
        "    'DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter',\n",
        "    'HellaSwag: Can a Machine Really Finish Your Sentence?',\n",
        "    'LLaMA: Open and Efficient Foundation Language Models',\n",
        "    'Measuring Massive Multitask Language Understanding',\n",
        "    'CodeNet: A Large-Scale AI for Code Dataset for Learning a Diversity of Coding Tasks',\n",
        "    'Task2Vec: Task Embedding for Meta-Learning',\n",
        "    'GLM-130B: An Open Bilingual Pre-trained Model',\n",
        "    'SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems',\n",
        "    \"Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism\",\n",
        "    \"PAL: Program-aided Language Models\",\n",
        "    \"RoBERTa: A Robustly Optimized BERT Pretraining Approach\",\n",
        "    \"DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LHM_8rNjSCaW"
      },
      "outputs": [],
      "source": [
        "# Filter the DataFrame to include only the required papers\n",
        "required_papers = df[df['title'].isin(required_paper_titles)]\n",
        "\n",
        "# Exclude the already selected papers to avoid duplicates and randomly sample ~40-50 papers\n",
        "remaining_papers = df[~df['title'].isin(required_paper_titles)].sample(n=40, random_state=123)\n",
        "\n",
        "# Concatenate the two DataFrames\n",
        "final_df = pd.concat([required_papers, remaining_papers], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iZ8GALGKSFkC"
      },
      "outputs": [],
      "source": [
        "# Prepare document objects from the dataset for indexing\n",
        "documents = [Document(text=content) for content in df['content']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-oiMETCycju1"
      },
      "outputs": [],
      "source": [
        "# Setup the embedding model\n",
        "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
        "\n",
        "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8ipRr3vH8pn3"
      },
      "outputs": [],
      "source": [
        "# from VS code notebook\n",
        "# Classic vector DB\n",
        "# Initialize a text splitter with hardcoded values for chunking documents\n",
        "parser = TokenTextSplitter(chunk_size=TOKEN_CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
        "nodes = parser.get_nodes_from_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIOtRhOAE0ZG"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Continue with your existing code\n",
        "# Instead of getting the collection, create it if it doesn't exist:\n",
        "chroma_collection = chroma_client.get_or_create_collection(\"ai_arxiv_full\")\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "# Reduce the batch size for embedding to avoid rate limits\n",
        "# You can experiment with different values until it works reliably\n",
        "insert_batch_size = 10\n",
        "\n",
        "index = VectorStoreIndex(\n",
        "    nodes,\n",
        "    storage_context=storage_context,\n",
        "    embed_model=embed_model,\n",
        "    use_async=True,\n",
        "    insert_batch_size=insert_batch_size # Add this line to control the batch size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7aClpyRA2s_"
      },
      "outputs": [],
      "source": [
        "# import nest_asyncio\n",
        "# nest_asyncio.apply()\n",
        "\n",
        "# # Continue with your existing code\n",
        "# # Instead of getting the collection, create it if it doesn't exist:\n",
        "# chroma_collection = chroma_client.get_or_create_collection(\"ai_arxiv_full\")\n",
        "# vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "# storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "# index = VectorStoreIndex(\n",
        "#     nodes,\n",
        "#     storage_context=storage_context,\n",
        "#     embed_model=embed_model,\n",
        "#     use_async=True\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePI4Lt_eAhDj"
      },
      "outputs": [],
      "source": [
        "# import nest_asyncio\n",
        "# nest_asyncio.apply()\n",
        "\n",
        "# # Continue with your existing code\n",
        "# chroma_collection = chroma_client.get_collection(\"ai_arxiv_full\")\n",
        "# vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "# storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "# index = VectorStoreIndex(\n",
        "#     nodes,\n",
        "#     storage_context=storage_context,\n",
        "#     embed_model=embed_model,\n",
        "#     use_async=True\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVFKJhgbcqLZ"
      },
      "outputs": [],
      "source": [
        "# Classic vector DB\n",
        "# # Initialize a text splitter with hardcoded values for chunking documents\n",
        "# parser = TokenTextSplitter(chunk_size=TOKEN_CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
        "# nodes = parser.get_nodes_from_documents(documents)\n",
        "\n",
        "# chroma_collection = chroma_client.create_collection(\"ai_arxiv_full\")\n",
        "\n",
        "# vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "\n",
        "# storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "# index = VectorStoreIndex(\n",
        "#     nodes, storage_context=storage_context,\n",
        "#     embed_model=embed_model,\n",
        "#     use_async=True\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GICuK61AzAM"
      },
      "outputs": [],
      "source": [
        "# # !pip install nest_asyncio\n",
        "# import nest_asyncio\n",
        "# nest_asyncio.apply()\n",
        "\n",
        "# # Classic vector DB\n",
        "# # Initialize a text splitter with hardcoded values for chunking documents\n",
        "# parser = TokenTextSplitter(chunk_size=TOKEN_CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
        "# nodes = parser.get_nodes_from_documents(documents)\n",
        "\n",
        "# # Instead of creating a new collection, try to get the existing one.\n",
        "# # If it doesn't exist, it will be created.\n",
        "# chroma_collection = chroma_client.get_or_create_collection(\"ai_arxiv_full\")\n",
        "\n",
        "# vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "\n",
        "# storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "# # Remove use_async=True to avoid nested event loop issues.\n",
        "# index = VectorStoreIndex(\n",
        "#     nodes, storage_context=storage_context,\n",
        "#     embed_model=embed_model\n",
        "#     # use_async=True  # Removed this line\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBMP706Hlk_z"
      },
      "outputs": [],
      "source": [
        "# !pip install nest_asyncio\n",
        "# import nest_asyncio\n",
        "# nest_asyncio.apply()\n",
        "\n",
        "# # Classic vector DB\n",
        "# # Initialize a text splitter with hardcoded values for chunking documents\n",
        "# parser = TokenTextSplitter(chunk_size=TOKEN_CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
        "# nodes = parser.get_nodes_from_documents(documents)\n",
        "\n",
        "# chroma_collection = chroma_client.create_collection(\"ai_arxiv_full\")\n",
        "\n",
        "# vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "\n",
        "# storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "# index = VectorStoreIndex(\n",
        "#     nodes, storage_context=storage_context,\n",
        "#     embed_model=embed_model,\n",
        "#     use_async=True # This line triggers the error because an event loop is already running in Jupyter\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mroWs-Odnm9M"
      },
      "outputs": [],
      "source": [
        "# !pip install nest_asyncio\n",
        "# import nest_asyncio\n",
        "# nest_asyncio.apply()\n",
        "\n",
        "# # Classic vector DB\n",
        "# # Initialize a text splitter with hardcoded values for chunking documents\n",
        "# parser = TokenTextSplitter(chunk_size=TOKEN_CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
        "# nodes = parser.get_nodes_from_documents(documents)\n",
        "\n",
        "# # Instead of creating a new collection, try to get the existing one.\n",
        "# # If it doesn't exist, it will be created.\n",
        "# chroma_collection = chroma_client.get_or_create_collection(\"ai_arxiv_full\")\n",
        "\n",
        "# vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "\n",
        "# storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "# index = VectorStoreIndex(\n",
        "#     nodes, storage_context=storage_context,\n",
        "#     embed_model=embed_model,\n",
        "#     use_async=True # This line triggers the error because an event loop is already running in Jupyter\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PThaz499ll0z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vVTa51vLMQZqca5YBz1M7YqbLPW7hT9_",
      "authorship_tag": "ABX9TyMEmKa4jNtMHRWBbRqWlKeB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}