{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vVTa51vLMQZqca5YBz1M7YqbLPW7hT9_",
      "authorship_tag": "ABX9TyMxFMt2HV8szEzGH6jXGgYx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6eb437709a4a422d92e81406af216443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da5a095d9bbb4aaf8144f7c03a7eaefd",
              "IPY_MODEL_d32494aecc934f3a90be522439b42e42",
              "IPY_MODEL_e1c198cea35848bb8bfa48f950a92964"
            ],
            "layout": "IPY_MODEL_c093762f9f914feabddcdb33a075cb83"
          }
        },
        "da5a095d9bbb4aaf8144f7c03a7eaefd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf7df60a7eff4e60ac87d689476fc6d6",
            "placeholder": "​",
            "style": "IPY_MODEL_71016c474df84be2968124ee71a25d6e",
            "value": "README.md: 100%"
          }
        },
        "d32494aecc934f3a90be522439b42e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cca139ede46b456e8e12b22dd481fb3f",
            "max": 267,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0a2689c8a9b443093f738a07e662eaf",
            "value": 267
          }
        },
        "e1c198cea35848bb8bfa48f950a92964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d322665782d84360ab01da7838e58e62",
            "placeholder": "​",
            "style": "IPY_MODEL_d4394e28127249549c1a14a72c55b916",
            "value": " 267/267 [00:00&lt;00:00, 11.5kB/s]"
          }
        },
        "c093762f9f914feabddcdb33a075cb83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf7df60a7eff4e60ac87d689476fc6d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71016c474df84be2968124ee71a25d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cca139ede46b456e8e12b22dd481fb3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0a2689c8a9b443093f738a07e662eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d322665782d84360ab01da7838e58e62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4394e28127249549c1a14a72c55b916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bb6f6cb27e24eb3b547146e213ac543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_012765be23e743c295ba58678e87cc99",
              "IPY_MODEL_3dfe050eded94eceadcae1cf1c65c333",
              "IPY_MODEL_5f387f8402784e1a9dfcda0c86e26f1d"
            ],
            "layout": "IPY_MODEL_2bb1a387b41b468eaf742ce36ab0de0b"
          }
        },
        "012765be23e743c295ba58678e87cc99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60e525b47bcc43d78c96b454bcf8e9f2",
            "placeholder": "​",
            "style": "IPY_MODEL_a59e9817793e429786eea2a16796cd41",
            "value": "train.jsonl: 100%"
          }
        },
        "3dfe050eded94eceadcae1cf1c65c333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4757cd1d49441eb9ad2ff0a0fd0c0b5",
            "max": 38780102,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de439bb549aa4ea39f32aef466be17f6",
            "value": 38780102
          }
        },
        "5f387f8402784e1a9dfcda0c86e26f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1e1a594448c4687b90c6c66e098ae2b",
            "placeholder": "​",
            "style": "IPY_MODEL_facdccf28e4f4526b675309a2ba6cb78",
            "value": " 38.8M/38.8M [00:00&lt;00:00, 106MB/s]"
          }
        },
        "2bb1a387b41b468eaf742ce36ab0de0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60e525b47bcc43d78c96b454bcf8e9f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a59e9817793e429786eea2a16796cd41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4757cd1d49441eb9ad2ff0a0fd0c0b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de439bb549aa4ea39f32aef466be17f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1e1a594448c4687b90c6c66e098ae2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "facdccf28e4f4526b675309a2ba6cb78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f95d555577ca4fbabc461401b1668906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7e3318caf3840f690c8e192c9cb3265",
              "IPY_MODEL_9c3221fd4440408d980bc943657b2fd1",
              "IPY_MODEL_dbb8512e4fce43339ada93c784ec9071"
            ],
            "layout": "IPY_MODEL_64338e3c75d240fb9c414274b8bce15d"
          }
        },
        "c7e3318caf3840f690c8e192c9cb3265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10029bdaf2954ab89a54b36075f991bf",
            "placeholder": "​",
            "style": "IPY_MODEL_37cbcabd9f594e9db843df9d1e1c0b00",
            "value": "Generating train split: 100%"
          }
        },
        "9c3221fd4440408d980bc943657b2fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_957c89a8a6c5470e8add6377fff06939",
            "max": 423,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ee297c718c64d2098e37195a7998cc5",
            "value": 423
          }
        },
        "dbb8512e4fce43339ada93c784ec9071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_464c23a4f224476da591dc8c80bc284f",
            "placeholder": "​",
            "style": "IPY_MODEL_8e398d27b3314d999769583d0c0d456c",
            "value": " 423/423 [00:00&lt;00:00, 641.05 examples/s]"
          }
        },
        "64338e3c75d240fb9c414274b8bce15d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10029bdaf2954ab89a54b36075f991bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37cbcabd9f594e9db843df9d1e1c0b00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "957c89a8a6c5470e8add6377fff06939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ee297c718c64d2098e37195a7998cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "464c23a4f224476da591dc8c80bc284f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e398d27b3314d999769583d0c0d456c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Vector DB for ARGOG Paper"
      ],
      "metadata": {
        "id": "Y2xB8tzXXj32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # install packages if they dont exist:\n",
        "# import subprocess\n",
        "# import sys\n",
        "\n",
        "# # Function to install a package if not already installed\n",
        "# def install_package(package_name, import_name=None):\n",
        "#     try:\n",
        "#         if import_name is None:\n",
        "#             import_name = package_name\n",
        "#         __import__(import_name)\n",
        "#     except ImportError:\n",
        "#         print(f\"{package_name} not found. Installing...\")\n",
        "#         subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
        "#     else:\n",
        "#         print(f\"{package_name} is already installed.\")\n",
        "\n",
        "# # List of packages to install with their import names if different\n",
        "# packages = [\n",
        "#     (\"datasets\", \"datasets\"),\n",
        "#     (\"pandas\", \"pandas\"),\n",
        "#     (\"llama-index\", \"llama_index\"),\n",
        "#     (\"chromadb\", \"chromadb\"),\n",
        "#     (\"openai\", \"openai\"),\n",
        "#     (\"dotenv\", \"dotenv\"),\n",
        "#     (\"llama_index.vector_stores\", \"llama_index.vector_stores\"),\n",
        "#     # (\"utils\", \"utils\")\n",
        "\n",
        "# ]\n",
        "\n",
        "# # Install each package\n",
        "# for package_name, import_name in packages:\n",
        "#     install_package(package_name, import_name)\n",
        "\n",
        "# # Check for `utils` module, typically custom or local\n",
        "# drive.mount('/content/drive')\n",
        "# import sys\n",
        "# sys.path.append('/content/drive/MyDrive/Colab Notebooks/ARGOG')\n",
        "# try:\n",
        "#     import utils\n",
        "# except ImportError:\n",
        "#     print(\"The 'utils' module is not found. Make sure it's available in your environment or install it manually.\")\n"
      ],
      "metadata": {
        "id": "d3rGp48GbBYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# install packages if they dont exist:\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Function to install a package if not already installed\n",
        "def install_package(package_name, import_name=None):\n",
        "    try:\n",
        "        if import_name is None:\n",
        "            import_name = package_name\n",
        "        # Use __import__ for top-level modules, import for submodules\n",
        "        if \".\" in import_name:\n",
        "            exec(f\"from {import_name.rsplit('.', 1)[0]} import {import_name.rsplit('.', 1)[1]}\")\n",
        "        else:\n",
        "            __import__(import_name)\n",
        "    except ImportError:\n",
        "        print(f\"{package_name} not found. Installing...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
        "    else:\n",
        "        print(f\"{package_name} is already installed.\")\n",
        "\n",
        "# List of packages to install with their import names if different\n",
        "packages = [\n",
        "    (\"datasets\", \"datasets\"),\n",
        "    (\"pandas\", \"pandas\"),\n",
        "    (\"llama-index\", \"llama_index\"),\n",
        "    (\"chromadb\", \"chromadb\"),\n",
        "    (\"openai\", \"openai\"),\n",
        "    (\"dotenv\", \"dotenv\"),\n",
        "    (\"llama-index-vector-stores-postgres\", \"llama_index.vector_stores\"), # Install the postgres vector store if you intend to use it\n",
        "    (\"llama-index-vector-stores-chroma\", \"llama-index-vector-stores-chroma\")\n",
        "\n",
        "]\n",
        "\n",
        "# Install each package\n",
        "for package_name, import_name in packages:\n",
        "    install_package(package_name, import_name)\n",
        "\n",
        "# Check for `utils` module, typically custom or local\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/ARGOG')\n",
        "try:\n",
        "    import utils\n",
        "except ImportError:\n",
        "    print(\"The 'utils' module is not found. Make sure it's available in your environment or install it manually.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb6x5_fwZhgY",
        "outputId": "82bbe66c-cd37-44e0-a2ed-65c0ab1c8a5c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasets not found. Installing...\n",
            "pandas is already installed.\n",
            "llama-index not found. Installing...\n",
            "chromadb not found. Installing...\n",
            "openai is already installed.\n",
            "dotenv is already installed.\n",
            "llama-index-vector-stores-postgres not found. Installing...\n",
            "llama-index-vector-stores-chroma not found. Installing...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries for loading datasets, data manipulation, document processing, vector storage, and embeddings.\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "from llama_index.core import Document, StorageContext, VectorStoreIndex\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
        "import chromadb\n",
        "from llama_index.core.node_parser import TokenTextSplitter\n",
        "from utils import chunked_iterable, load_config\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "import openai\n",
        "import os\n",
        "from utils import *\n",
        "\n"
      ],
      "metadata": {
        "id": "GeeZunHHev5Q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Verify the directory exists\n",
        "argog_path = '/content/drive/MyDrive/Colab Notebooks/ARGOG'\n",
        "if os.path.exists(argog_path):\n",
        "    print(f\"Directory exists: {argog_path}\")\n",
        "else:\n",
        "    print(f\"Directory does not exist: {argog_path}\")\n",
        "\n",
        "# Path to the .env file\n",
        "env_path = '/content/drive/MyDrive/Colab Notebooks/ARGOG/.env'\n",
        "\n",
        "# Load the .env file\n",
        "load_dotenv(dotenv_path=env_path)\n",
        "\n",
        "# Hardcoded values for easy adjustment\n",
        "CHUNK_SIZE = 1000 #only for db upload\n",
        "TOKEN_CHUNK_SIZE = 512\n",
        "CHUNK_OVERLAP = 50\n",
        "\n",
        "# Load the config file\n",
        "load_config()\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "print(openai.api_key)\n",
        "hf_read_token = os.getenv(\"HF_READ_TOKEN\")\n",
        "from huggingface_hub import login\n",
        "login(hf_read_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogkjsIGaaLQt",
        "outputId": "5892f759-703c-42d3-b897-795d6790a62a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Directory exists: /content/drive/MyDrive/Colab Notebooks/ARGOG\n",
            "sk-proj-NedhPl47SBdpZvVsIe2KT3BlbkFJspbYIje2ZfdzTrhdPqP5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset and convert to DataFrame for easier manipulation\n",
        "dataset = load_dataset(\"jamescalam/ai-arxiv\")\n",
        "df = pd.DataFrame(dataset['train'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278,
          "referenced_widgets": [
            "6eb437709a4a422d92e81406af216443",
            "da5a095d9bbb4aaf8144f7c03a7eaefd",
            "d32494aecc934f3a90be522439b42e42",
            "e1c198cea35848bb8bfa48f950a92964",
            "c093762f9f914feabddcdb33a075cb83",
            "bf7df60a7eff4e60ac87d689476fc6d6",
            "71016c474df84be2968124ee71a25d6e",
            "cca139ede46b456e8e12b22dd481fb3f",
            "e0a2689c8a9b443093f738a07e662eaf",
            "d322665782d84360ab01da7838e58e62",
            "d4394e28127249549c1a14a72c55b916",
            "0bb6f6cb27e24eb3b547146e213ac543",
            "012765be23e743c295ba58678e87cc99",
            "3dfe050eded94eceadcae1cf1c65c333",
            "5f387f8402784e1a9dfcda0c86e26f1d",
            "2bb1a387b41b468eaf742ce36ab0de0b",
            "60e525b47bcc43d78c96b454bcf8e9f2",
            "a59e9817793e429786eea2a16796cd41",
            "c4757cd1d49441eb9ad2ff0a0fd0c0b5",
            "de439bb549aa4ea39f32aef466be17f6",
            "b1e1a594448c4687b90c6c66e098ae2b",
            "facdccf28e4f4526b675309a2ba6cb78",
            "f95d555577ca4fbabc461401b1668906",
            "c7e3318caf3840f690c8e192c9cb3265",
            "9c3221fd4440408d980bc943657b2fd1",
            "dbb8512e4fce43339ada93c784ec9071",
            "64338e3c75d240fb9c414274b8bce15d",
            "10029bdaf2954ab89a54b36075f991bf",
            "37cbcabd9f594e9db843df9d1e1c0b00",
            "957c89a8a6c5470e8add6377fff06939",
            "9ee297c718c64d2098e37195a7998cc5",
            "464c23a4f224476da591dc8c80bc284f",
            "8e398d27b3314d999769583d0c0d456c"
          ]
        },
        "id": "gA5zqiw6Vod6",
        "outputId": "a54f79df-65c6-4ca7-b92e-a34c5a82d3d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/267 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6eb437709a4a422d92e81406af216443"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train.jsonl:   0%|          | 0.00/38.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bb6f6cb27e24eb3b547146e213ac543"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/423 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f95d555577ca4fbabc461401b1668906"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the titles of the required papers\n",
        "required_paper_titles = [\n",
        "    'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding',\n",
        "    'DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter',\n",
        "    'HellaSwag: Can a Machine Really Finish Your Sentence?',\n",
        "    'LLaMA: Open and Efficient Foundation Language Models',\n",
        "    'Measuring Massive Multitask Language Understanding',\n",
        "    'CodeNet: A Large-Scale AI for Code Dataset for Learning a Diversity of Coding Tasks',\n",
        "    'Task2Vec: Task Embedding for Meta-Learning',\n",
        "    'GLM-130B: An Open Bilingual Pre-trained Model',\n",
        "    'SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems',\n",
        "    \"Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism\",\n",
        "    \"PAL: Program-aided Language Models\",\n",
        "    \"RoBERTa: A Robustly Optimized BERT Pretraining Approach\",\n",
        "    \"DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature\"\n",
        "]"
      ],
      "metadata": {
        "id": "AQR29bCoQoau"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame to include only the required papers\n",
        "required_papers = df[df['title'].isin(required_paper_titles)]\n",
        "\n",
        "# Exclude the already selected papers to avoid duplicates and randomly sample ~40-50 papers\n",
        "remaining_papers = df[~df['title'].isin(required_paper_titles)].sample(n=40, random_state=123)\n",
        "\n",
        "# Concatenate the two DataFrames\n",
        "final_df = pd.concat([required_papers, remaining_papers], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "LHM_8rNjSCaW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare document objects from the dataset for indexing\n",
        "documents = [Document(text=content) for content in df['content']]\n"
      ],
      "metadata": {
        "id": "iZ8GALGKSFkC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the embedding model\n",
        "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
        "\n",
        "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n"
      ],
      "metadata": {
        "id": "-oiMETCycju1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classic vector DB\n",
        "# Initialize a text splitter with hardcoded values for chunking documents\n",
        "parser = TokenTextSplitter(chunk_size=TOKEN_CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
        "nodes = parser.get_nodes_from_documents(documents)\n",
        "\n",
        "chroma_collection = chroma_client.create_collection(\"ai_arxiv_full\")\n",
        "\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "index = VectorStoreIndex(\n",
        "    nodes, storage_context=storage_context,\n",
        "    embed_model=embed_model,\n",
        "    use_async=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "vVFKJhgbcqLZ",
        "outputId": "6c9586d7-c9dd-4684-835b-46b5bcc32690"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Detected nested async. Please use nest_asyncio.apply() to allow nested event loops.Or, use async entry methods like `aquery()`, `aretriever`, `achat`, etc.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/async_utils.py\u001b[0m in \u001b[0;36masyncio_run\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# If we're here, there's an existing loop but it's not running\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/base_events.py\u001b[0m in \u001b[0;36m_check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This event loop is already running'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/async_utils.py\u001b[0m in \u001b[0;36masyncio_run\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m     34\u001b[0m             \"asyncio.run() cannot be called from a running event loop\")\n",
            "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-48d008d1673a>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mstorage_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStorageContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_store\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvector_store\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m index = VectorStoreIndex(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0membed_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membed_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/indices/vector_store/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insert_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsert_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mindex_struct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_struct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/indices/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex_struct\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 index_struct = self.build_index_from_nodes(\n\u001b[0m\u001b[1;32m     78\u001b[0m                     \u001b[0mnodes\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/indices/vector_store/base.py\u001b[0m in \u001b[0;36mbuild_index_from_nodes\u001b[0;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Some nodes are missing content, skipping them...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_index_from_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minsert_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_insert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseNode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minsert_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/indices/vector_store/base.py\u001b[0m in \u001b[0;36m_build_index_from_nodes\u001b[0;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m                 )\n\u001b[1;32m    276\u001b[0m             ]\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0mrun_async_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             self._add_nodes_to_index(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/async_utils.py\u001b[0m in \u001b[0;36mrun_async_tasks\u001b[0;34m(tasks, show_progress, progress_bar_desc)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtasks_to_execute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/async_utils.py\u001b[0m in \u001b[0;36masyncio_run\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0;34m\"Detected nested async. Please use nest_asyncio.apply() to allow nested event loops.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;34m\"Or, use async entry methods like `aquery()`, `aretriever`, `achat`, etc.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Detected nested async. Please use nest_asyncio.apply() to allow nested event loops.Or, use async entry methods like `aquery()`, `aretriever`, `achat`, etc."
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install nest_asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Classic vector DB\n",
        "# Initialize a text splitter with hardcoded values for chunking documents\n",
        "parser = TokenTextSplitter(chunk_size=TOKEN_CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
        "nodes = parser.get_nodes_from_documents(documents)\n",
        "\n",
        "chroma_collection = chroma_client.create_collection(\"ai_arxiv_full\")\n",
        "\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "index = VectorStoreIndex(\n",
        "    nodes, storage_context=storage_context,\n",
        "    embed_model=embed_model,\n",
        "    use_async=True # This line triggers the error because an event loop is already running in Jupyter\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "LBMP706Hlk_z",
        "outputId": "2ccf38b8-921a-4e7b-af25-752290058bed"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UniqueConstraintError",
          "evalue": "Collection ai_arxiv_full already exists",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUniqueConstraintError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2c9996cd26f1>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nodes_from_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mchroma_collection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchroma_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ai_arxiv_full\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mvector_store\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChromaVectorStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchroma_collection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchroma_collection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/api/client.py\u001b[0m in \u001b[0;36mcreate_collection\u001b[0;34m(self, name, configuration, metadata, embedding_function, data_loader, get_or_create)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mget_or_create\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     ) -> Collection:\n\u001b[0;32m--> 147\u001b[0;31m         model = self._server.create_collection(\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/telemetry/opentelemetry/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;32mglobal\u001b[0m \u001b[0mtracer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgranularity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtrace_granularity\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mgranularity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtracer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/api/segment.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rate_limit_enforcer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate_limit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/rate_limit/simple_rate_limit/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/api/segment.py\u001b[0m in \u001b[0;36mcreate_collection\u001b[0;34m(self, name, configuration, metadata, get_or_create, tenant, database)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# TODO: Let sysdb create the collection directly from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         coll, created = self._sysdb.create_collection(\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/telemetry/opentelemetry/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;32mglobal\u001b[0m \u001b[0mtracer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgranularity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtrace_granularity\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mgranularity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtracer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/db/mixins/sysdb.py\u001b[0m in \u001b[0;36mcreate_collection\u001b[0;34m(self, id, name, configuration, segments, metadata, dimension, get_or_create, tenant, database)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 )\n\u001b[1;32m    240\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mUniqueConstraintError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Collection {name} already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         collection = Collection(\n",
            "\u001b[0;31mUniqueConstraintError\u001b[0m: Collection ai_arxiv_full already exists"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install nest_asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Classic vector DB\n",
        "# Initialize a text splitter with hardcoded values for chunking documents\n",
        "parser = TokenTextSplitter(chunk_size=TOKEN_CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
        "nodes = parser.get_nodes_from_documents(documents)\n",
        "\n",
        "# Instead of creating a new collection, try to get the existing one.\n",
        "# If it doesn't exist, it will be created.\n",
        "chroma_collection = chroma_client.get_or_create_collection(\"ai_arxiv_full\")\n",
        "\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "index = VectorStoreIndex(\n",
        "    nodes, storage_context=storage_context,\n",
        "    embed_model=embed_model,\n",
        "    use_async=True # This line triggers the error because an event loop is already running in Jupyter\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mroWs-Odnm9M",
        "outputId": "e82667ff-f207-453f-f5ad-33705cfdaca1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:331: RuntimeWarning: coroutine 'run_async_tasks.<locals>._gather' was never awaited\n",
            "  return hasattr(instance, '__pydantic_validator__') and super().__instancecheck__(instance)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:331: RuntimeWarning: coroutine 'VectorStoreIndex._async_add_nodes_to_index' was never awaited\n",
            "  return hasattr(instance, '__pydantic_validator__') and super().__instancecheck__(instance)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.9208985849544716 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 978495, Requested 48264. Please try again in 1.605s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.09798575839059587 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 966937, Requested 50228. Please try again in 1.029s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.11000712661107115 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 1000000, Requested 40163. Please try again in 2.409s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.9176410792655151 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 1000000, Requested 42660. Please try again in 2.559s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.22491414860499936 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 1000000, Requested 36456. Please try again in 2.187s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.5580293483025613 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 984739, Requested 46238. Please try again in 1.858s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.09632710589221838 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 995367, Requested 48199. Please try again in 2.613s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.5514471564476344 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 1000000, Requested 46992. Please try again in 2.819s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.4767125346814881 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 1000000, Requested 37140. Please try again in 2.228s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.14163856062027524 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 1000000, Requested 44850. Please try again in 2.691s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.803484897002533 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 1000000, Requested 44865. Please try again in 2.691s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.5895438535160976 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 987009, Requested 40674. Please try again in 1.66s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.5586657073084466 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 962380, Requested 43285. Please try again in 339ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.6435710451674287 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 991985, Requested 44809. Please try again in 2.207s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.4274946311054567 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 988834, Requested 47992. Please try again in 2.209s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.20583095475223023 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 986139, Requested 48188. Please try again in 2.059s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.16836877207790735 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 1000000, Requested 42149. Please try again in 2.528s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.16351027064061585 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 1000000, Requested 28193. Please try again in 1.691s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.8103964368691539 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 984776, Requested 40700. Please try again in 1.528s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.21897477605075777 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 981163, Requested 42413. Please try again in 1.414s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._aget_text_embeddings.<locals>._retryable_aget_embeddings in 0.7891325460931231 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-3-large in organization org-oQuebWhpieTzpJtTlWIVROVj on tokens per min (TPM): Limit 1000000, Used 982559, Requested 43857. Please try again in 1.584s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PThaz499ll0z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}