{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMm7S/ubP9LvPF/yBKlcqbg"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Main code for ARGOG\n",
        "Assumes all fiels in Google Drive."
      ],
      "metadata": {
        "id": "9EMzt-lgC6dD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install packages if they dont exist:\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Function to install a package if not already installed\n",
        "def install_package(package_name, import_name=None):\n",
        "    try:\n",
        "        if import_name is None:\n",
        "            import_name = package_name\n",
        "        # Use __import__ for top-level modules, import for submodules\n",
        "        if \".\" in import_name:\n",
        "            exec(f\"from {import_name.rsplit('.', 1)[0]} import {import_name.rsplit('.', 1)[1]}\")\n",
        "        else:\n",
        "            __import__(import_name)\n",
        "    except ImportError:\n",
        "        print(f\"{package_name} not found. Installing...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
        "    else:\n",
        "        print(f\"{package_name} is already installed.\")\n",
        "\n",
        "# List of packages to install with their import names if different\n",
        "packages = [\n",
        "    (\"datasets\", \"datasets\"),\n",
        "    (\"pandas\", \"pandas\"),\n",
        "    (\"llama-index\", \"llama_index\"),\n",
        "    (\"chromadb\", \"chromadb\"),\n",
        "    (\"openai\", \"openai\"),\n",
        "    (\"dotenv\", \"dotenv\"),\n",
        "    (\"llama-index-vector-stores-postgres\", \"llama_index.vector_stores\"), # Install the postgres vector store if you intend to use it\n",
        "    (\"llama-index-vector-stores-chroma\", \"llama-index-vector-stores-chroma\"),\n",
        "    (\"nest_asyncio\", \"nest_asyncio\"),\n",
        "    (\"tenacity\", \"tenacity\"),\n",
        "    (\"llama_index\", \"llama_index\"),\n",
        "    (\"tonic_validate\", \"tonic_validate\"),\n",
        "    (\"os\",\"os\"),\n",
        "    (\"subprocess\", \"subprocess\"),\n",
        "    (\"sys\", \"sys\")\n",
        "\n",
        "]\n",
        "\n",
        "# Install each package\n",
        "for package_name, import_name in packages:\n",
        "    install_package(package_name, import_name)\n",
        "\n",
        "from llama_index.llms import OpenAI # Import the OpenAI class\n",
        "from llama_index.embeddings import OpenAIEmbedding # Import OpenAIEmbedding\n",
        "from llama_index.core import Settings # Import Settings\n",
        "from llama_index import ServiceContext # Import ServiceContext\n",
        "from llama_index.vector_stores import ChromaVectorStore # Import ChromaVectorStore\n",
        "import openai\n",
        "from dotenv import load_dotenv # Import load_dotenv from dotenv\n",
        "from tonic_validate import ValidateApi # Import ValidateApi from tonic_validate\n",
        "\n",
        "\n",
        "# Check for `utils` module, typically custom or local\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/ARGOG')\n",
        "try:\n",
        "    import utils\n",
        "except ImportError:\n",
        "    print(\"The 'utils' module is not found. Make sure it's available in your environment or install it manually.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "VNT4-F6JDj3M",
        "outputId": "5193ee41-d4c8-4a18-9869-1b9c36b9ae45"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasets is already installed.\n",
            "pandas is already installed.\n",
            "llama-index is already installed.\n",
            "chromadb is already installed.\n",
            "openai is already installed.\n",
            "dotenv is already installed.\n",
            "llama-index-vector-stores-postgres is already installed.\n",
            "llama-index-vector-stores-chroma not found. Installing...\n",
            "nest_asyncio is already installed.\n",
            "tenacity is already installed.\n",
            "llama_index is already installed.\n",
            "tonic_validate is already installed.\n",
            "os is already installed.\n",
            "subprocess is already installed.\n",
            "sys is already installed.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'OpenAI' from 'llama_index.llms' (unknown location)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-5495e2aa030b>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0minstall_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m \u001b[0;31m# Import the OpenAI class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIEmbedding\u001b[0m \u001b[0;31m# Import OpenAIEmbedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSettings\u001b[0m \u001b[0;31m# Import Settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'OpenAI' from 'llama_index.llms' (unknown location)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os # Import the os module\n",
        "\n",
        "# Verify the directory exists\n",
        "argog_path = '/content/drive/MyDrive/Colab Notebooks/ARGOG'\n",
        "if os.path.exists(argog_path):\n",
        "    print(f\"Directory exists: {argog_path}\")\n",
        "else:\n",
        "    print(f\"Directory does not exist: {argog_path}\")\n",
        "\n",
        "# Path to the .env file\n",
        "env_path = '/content/drive/MyDrive/Colab Notebooks/ARGOG/.env'\n",
        "\n",
        "# Load the .env file\n",
        "load_dotenv(dotenv_path=env_path)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2EyWtBxFWBU",
        "outputId": "6cbca9c5-9689-4b3e-8ee5-3f89b4671a06"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Directory exists: /content/drive/MyDrive/Colab Notebooks/ARGOG\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the OpenAI API key for authentication.\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "tonic_validate_api_key = os.getenv(\"HASSAN_TONIC_VALIDATE_API1\")\n",
        "tonic_validate_project_key = os.getenv(\"HASSAN_TONIC_VALIDATE_PROJECT1\")\n",
        "tonic_validate_benchmark_key = os.getenv(\"HASSAN_TONIC_VALIDATE_BENCHMARK1\")\n",
        "validate_api = ValidateApi(tonic_validate_api_key)\n",
        "# print (f'{tonic_validate_api_key} {tonic_validate_project_key} {tonic_validate_benchmark_key}')\n",
        "cohere_api_key = os.getenv(\"HASSAN_COHERE_DEFAULT_API\")\n",
        "# print (f'{tonic_validate_api_key} {tonic_validate_project_key} {tonic_validate_benchmark_key}')\n",
        "# cohere_api_key"
      ],
      "metadata": {
        "id": "0reSO6sDGCGj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a config dictionary\n",
        "config = {\n",
        "    # 'cohere_api_key': os.getenv('COHERE_API_KEY'),\n",
        "    # 'another_setting': os.getenv('ANOTHER_SETTING'),\n",
        "    'tonic_validate_api_key': os.getenv(\"HASSAN_TONIC_VALIDATE_API1\"),\n",
        "    'tonic_validate_project_key':  os.getenv(\"HASSAN_TONIC_VALIDATE_PROJECT1\"),\n",
        "    'tonic_validate_benchmark_key':  os.getenv(\"HASSAN_TONIC_VALIDATE_BENCHMARK1\"),\n",
        "    'cohere_api_key':  os.getenv(\"HASSAN_COHERE_DEFAULT_API\")\n",
        "}\n",
        "\n",
        "# Print to verify\n",
        "# print(config)"
      ],
      "metadata": {
        "id": "VXd6trp-Gz0r"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Service context\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
        "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
        "# service_context = ServiceContext.from_defaults(llm = llm, embed_model = embed_model)\n",
        "# settings = Settings(llm=llm, embed_model=embed_model)\n",
        "Settings.llm = llm\n",
        "\n",
        "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "YXJLPAsWG6Kt",
        "outputId": "268fbb6a-9271-4478-b6a9-15091024276c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'OpenAI' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-a7937eee26a4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Service context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0membed_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAIEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-embedding-3-large\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSettings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'OpenAI' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wxtp0bh3CjXy"
      }
    }
  ]
}